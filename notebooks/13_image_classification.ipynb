{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification \n",
    "\n",
    "In image classification, we try to assign a class label to an image based on the prominent objects contained inside the image.\n",
    "\n",
    "Example:\n",
    "* Classifying images from a zoo according to the species\n",
    "* Classifying images of hand-written digits to the correct digit\n",
    "\n",
    "## What we'll be doing\n",
    "\n",
    "Digits (MNIST) with Logistic Regression!\n",
    "\n",
    "* Read images\n",
    "* Visualise them\n",
    "* Flatten the images\n",
    "* Resample for machine learning\n",
    "* Build Models\n",
    "* Predict on new data\n",
    "* Model assessment\n",
    "\n",
    "## Get the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DESCR': 'Optical Recognition of Handwritten Digits Data Set\\n'\n",
      "          '===================================================\\n'\n",
      "          '\\n'\n",
      "          'Notes\\n'\n",
      "          '-----\\n'\n",
      "          'Data Set Characteristics:\\n'\n",
      "          '    :Number of Instances: 5620\\n'\n",
      "          '    :Number of Attributes: 64\\n'\n",
      "          '    :Attribute Information: 8x8 image of integer pixels in the '\n",
      "          'range 0..16.\\n'\n",
      "          '    :Missing Attribute Values: None\\n'\n",
      "          \"    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n\"\n",
      "          '    :Date: July; 1998\\n'\n",
      "          '\\n'\n",
      "          'This is a copy of the test set of the UCI ML hand-written digits '\n",
      "          'datasets\\n'\n",
      "          'http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n'\n",
      "          '\\n'\n",
      "          'The data set contains images of hand-written digits: 10 classes '\n",
      "          'where\\n'\n",
      "          'each class refers to a digit.\\n'\n",
      "          '\\n'\n",
      "          'Preprocessing programs made available by NIST were used to extract\\n'\n",
      "          'normalized bitmaps of handwritten digits from a preprinted form. '\n",
      "          'From a\\n'\n",
      "          'total of 43 people, 30 contributed to the training set and '\n",
      "          'different 13\\n'\n",
      "          'to the test set. 32x32 bitmaps are divided into nonoverlapping '\n",
      "          'blocks of\\n'\n",
      "          '4x4 and the number of on pixels are counted in each block. This '\n",
      "          'generates\\n'\n",
      "          'an input matrix of 8x8 where each element is an integer in the '\n",
      "          'range\\n'\n",
      "          '0..16. This reduces dimensionality and gives invariance to small\\n'\n",
      "          'distortions.\\n'\n",
      "          '\\n'\n",
      "          'For info on NIST preprocessing routines, see M. D. Garris, J. L. '\n",
      "          'Blue, G.\\n'\n",
      "          'T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, '\n",
      "          'and C.\\n'\n",
      "          'L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR '\n",
      "          '5469,\\n'\n",
      "          '1994.\\n'\n",
      "          '\\n'\n",
      "          'References\\n'\n",
      "          '----------\\n'\n",
      "          '  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and '\n",
      "          'Their\\n'\n",
      "          '    Applications to Handwritten Digit Recognition, MSc Thesis, '\n",
      "          'Institute of\\n'\n",
      "          '    Graduate Studies in Science and Engineering, Bogazici '\n",
      "          'University.\\n'\n",
      "          '  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, '\n",
      "          'Kybernetika.\\n'\n",
      "          '  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai '\n",
      "          'Qin.\\n'\n",
      "          '    Linear dimensionalityreduction using relevance weighted LDA. '\n",
      "          'School of\\n'\n",
      "          '    Electrical and Electronic Engineering Nanyang Technological '\n",
      "          'University.\\n'\n",
      "          '    2005.\\n'\n",
      "          '  - Claudio Gentile. A New Approximate Maximal Margin '\n",
      "          'Classification\\n'\n",
      "          '    Algorithm. NIPS. 2000.\\n',\n",
      " 'data': array([[  0.,   0.,   5., ...,   0.,   0.,   0.],\n",
      "       [  0.,   0.,   0., ...,  10.,   0.,   0.],\n",
      "       [  0.,   0.,   0., ...,  16.,   9.,   0.],\n",
      "       ..., \n",
      "       [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "       [  0.,   0.,   2., ...,  12.,   0.,   0.],\n",
      "       [  0.,   0.,  10., ...,  12.,   1.,   0.]]),\n",
      " 'images': array([[[  0.,   0.,   5., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  13., ...,  15.,   5.,   0.],\n",
      "        [  0.,   3.,  15., ...,  11.,   8.,   0.],\n",
      "        ..., \n",
      "        [  0.,   4.,  11., ...,  12.,   7.,   0.],\n",
      "        [  0.,   2.,  14., ...,  12.,   0.,   0.],\n",
      "        [  0.,   0.,   6., ...,   0.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   0., ...,   5.,   0.,   0.],\n",
      "        [  0.,   0.,   0., ...,   9.,   0.,   0.],\n",
      "        [  0.,   0.,   3., ...,   6.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "        [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "        [  0.,   0.,   0., ...,  10.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   0., ...,  12.,   0.,   0.],\n",
      "        [  0.,   0.,   3., ...,  14.,   0.,   0.],\n",
      "        [  0.,   0.,   8., ...,  16.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   9.,  16., ...,   0.,   0.,   0.],\n",
      "        [  0.,   3.,  13., ...,  11.,   5.,   0.],\n",
      "        [  0.,   0.,   0., ...,  16.,   9.,   0.]],\n",
      "\n",
      "       ..., \n",
      "       [[  0.,   0.,   1., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  13., ...,   2.,   1.,   0.],\n",
      "        [  0.,   0.,  16., ...,  16.,   5.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,  16., ...,  15.,   0.,   0.],\n",
      "        [  0.,   0.,  15., ...,  16.,   0.,   0.],\n",
      "        [  0.,   0.,   2., ...,   6.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   2., ...,   0.,   0.,   0.],\n",
      "        [  0.,   0.,  14., ...,  15.,   1.,   0.],\n",
      "        [  0.,   4.,  16., ...,  16.,   7.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,   0., ...,  16.,   2.,   0.],\n",
      "        [  0.,   0.,   4., ...,  16.,   2.,   0.],\n",
      "        [  0.,   0.,   5., ...,  12.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,  10., ...,   1.,   0.,   0.],\n",
      "        [  0.,   2.,  16., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  15., ...,  15.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   4.,  16., ...,  16.,   6.,   0.],\n",
      "        [  0.,   8.,  16., ...,  16.,   8.,   0.],\n",
      "        [  0.,   1.,   8., ...,  12.,   1.,   0.]]]),\n",
      " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
      " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "pprint(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Images\n",
    "\n",
    "* The data that we are interested in is made of 8x8 images of digits.\n",
    "* Let's have a look at the first 8 images, stored in the `images` attribute of the dataset.\n",
    "* For these images, we know which digit they represent: it is given in the 'target' of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADuCAYAAAAZZe3jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112e5e438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:8]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten the Images\n",
    "\n",
    "To apply a classifier on this data, we need to flatten the image, to turn the data in a (samples, feature) matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier: a logistic regression classifier\n",
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[n_samples // 2:]\n",
    "predicted = classifier.predict(data[n_samples // 2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.97      0.96        88\n",
      "          1       0.86      0.89      0.88        91\n",
      "          2       0.98      0.98      0.98        86\n",
      "          3       0.99      0.82      0.90        91\n",
      "          4       0.99      0.93      0.96        92\n",
      "          5       0.83      0.90      0.86        91\n",
      "          6       0.94      0.99      0.96        91\n",
      "          7       0.98      0.89      0.93        89\n",
      "          8       0.89      0.88      0.88        88\n",
      "          9       0.83      0.92      0.87        92\n",
      "\n",
      "avg / total       0.92      0.92      0.92       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[85  0  0  0  1  1  1  0  0  0]\n",
      " [ 0 81  0  1  0  0  1  0  2  6]\n",
      " [ 2  0 84  0  0  0  0  0  0  0]\n",
      " [ 0  1  0 75  0  6  0  2  5  2]\n",
      " [ 1  2  0  0 86  0  1  0  0  2]\n",
      " [ 0  3  0  0  0 82  2  0  0  4]\n",
      " [ 0  0  1  0  0  0 90  0  0  0]\n",
      " [ 0  1  0  0  0  5  0 79  1  3]\n",
      " [ 0  5  1  0  0  3  1  0 77  1]\n",
      " [ 2  1  0  0  0  2  0  0  2 85]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.916573971079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %s\\n\" % (metrics.accuracy_score(expected, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMga3JFXmv4Na3tF5CqcBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11205b828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
